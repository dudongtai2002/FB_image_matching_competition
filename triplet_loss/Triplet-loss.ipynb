{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e505451c-d917-474a-a7ca-b96a0ad8be93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f6dd066-36bd-44ab-ab61-b423bde722cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'C:\\\\Data_Competitions\\\\Facebook image matching\\\\FB_image_matching_competition\\\\'\n",
    "data_directory = directory + 'data\\\\'\n",
    "training_image_path = data_directory + 'training_images\\\\'\n",
    "ref_image_path = data_directory + 'reference_images\\\\'\n",
    "query_image_path = data_directory + 'query_images\\\\'\n",
    "ground_truth_csv = directory + 'public_ground_truth.csv'\n",
    "from FBImageTriplet import FBImgMatchingDataSetTriplet\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdd23f62-b159-47cf-bdf7-cecf391df6c1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resnet18Triplet(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=512, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from resnet_triplet import Resnet18Triplet, Resnet34Triplet\n",
    "\n",
    "model = Resnet18Triplet()\n",
    "#print(model)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "238ef36b-1df5-46af-8183-ccf2c41d4bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_optimizer(optimizer, model, learning_rate):\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer_model = optim.SGD(\n",
    "            params=model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            momentum=0.9,\n",
    "            dampening=0,\n",
    "            nesterov=False,\n",
    "            weight_decay=1e-5\n",
    "        )\n",
    "\n",
    "    elif optimizer == \"adagrad\":\n",
    "        optimizer_model = optim.Adagrad(\n",
    "            params=model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            lr_decay=0,\n",
    "            initial_accumulator_value=0.1,\n",
    "            eps=1e-10,\n",
    "            weight_decay=1e-5\n",
    "        )\n",
    "\n",
    "    elif optimizer == \"rmsprop\":\n",
    "        optimizer_model = optim.RMSprop(\n",
    "            params=model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            alpha=0.99,\n",
    "            eps=1e-08,\n",
    "            momentum=0,\n",
    "            centered=False,\n",
    "            weight_decay=1e-5\n",
    "        )\n",
    "\n",
    "    elif optimizer == \"adam\":\n",
    "        optimizer_model = optim.Adam(\n",
    "            params=model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-08,\n",
    "            amsgrad=False,\n",
    "            weight_decay=1e-5\n",
    "        )\n",
    "\n",
    "    return optimizer_model\n",
    "\n",
    "\n",
    "\n",
    "# Set optimizer\n",
    "optimizer_model = set_optimizer(\n",
    "    optimizer=\"sgd\",\n",
    "    model=model,\n",
    "    learning_rate=0.075\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0422444f-d69a-4bde-9667-8ea2b87dfce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load existing model dict:\n",
    "resume_path = directory + 'triplet_loss\\\\resnet18_semihard12.pt'\n",
    "checkpoint = torch.load(resume_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer_model.load_state_dict(checkpoint['optimizer_model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25c95861-ae94-4fa4-998f-a791baeeac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.distance import PairwiseDistance\n",
    "\n",
    "def generate_triplets(anchor_embedding, pos_embedding, neg_embedding, margin = 0.3, use_semihard_negatives = True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        anchor_embedding: torch tensor, size: ([number_of_anchor_embeddings, embedding_dimension]), stored in cuda\n",
    "        pos_embedding: torch tensor, size: ([number_of_pos_embeddings(in this dataset, it is the same as number of anchors), embedding_dimension]), stored in cuda\n",
    "        neg_embedding: torch tensor, size: ([number_of_negative_embeddings, embedding_dimension]), stored in cuda\n",
    "        margin: used to choose the right semi-hard triplet, default is 0.3\n",
    "            \n",
    "    This function is used to select one or more valid smihard triplets for each (anchor_embedding, pos_embedding) pair.\n",
    "    all 3 returned tensor is of the same size: ([number_of_chosen_embeddings, embedding_dimension])\n",
    "    \"\"\"\n",
    "    pdist = PairwiseDistance(p=2)\n",
    "    pos_dist = pdist.forward(anchor_embedding, pos_embedding) # calculate pairwise L2 distance between anchor_embedding and pos_embedding, return tensor size: torch.Size([number of anchor/pos embeddings])\n",
    "    neg_dist = torch.cdist(anchor_embedding, neg_embedding) # calculate L2 distance between possible anchor_embeding and all neg_embedding, return tensor size:torch.Size([number of anchor/pos embeddings, number of neg embeddings])\n",
    "    \n",
    "    # reshape pos_dist\n",
    "    pos_dist_reshape = pos_dist[:,None] - neg_dist + neg_dist  # repeat the pos_dist, copy each row \n",
    "    \n",
    "    first_condition = neg_dist - pos_dist_reshape < margin\n",
    "    if use_semihard_negatives:\n",
    "    # semihard triplets\n",
    "        second_condition = pos_dist_reshape < neg_dist\n",
    "        all_condition = torch.logical_and(first_condition, second_condition)\n",
    "    else:\n",
    "    # hard triplets\n",
    "        all_condition = first_condition\n",
    "        \n",
    "    # triplets_index: tuple(tensor[] (size: number of triplets), tensor[] (size: number of triplets)), \n",
    "    # this is the index for all valid entries chosen in neg_dists and reshaped pos_dist, the first entry would be the row index and second is the column. \n",
    "    # as can be seen, the row index here is the corresponding index for anchor/pos embedding, the column index is the corresponding index for negative embedding\n",
    "    triplets_index = torch.where(all_condition == 1)  \n",
    "    \n",
    "    # use the row index to get selected anchor embeddings and positive embeddings\n",
    "    selected_anchor_embeddings = anchor_embedding[triplets_index[0]]\n",
    "    selected_pos_embeddings = pos_embedding[triplets_index[0]]\n",
    "    \n",
    "    # use the column index to get select negatie embeddings\n",
    "    selected_neg_embeddings = neg_embedding[triplets_index[1]]\n",
    "    \n",
    "    # print(\"selected {} semihard triplets\".format(selected_anchor_embeddings.size(0)))  # these 3 selected embeddings should have the same size, so doesn't matter which one to use\n",
    "        \n",
    "    return selected_anchor_embeddings, selected_pos_embeddings, selected_neg_embeddings  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f2e8eae-d4dd-4554-be95-5021cc95c81c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detect 50000 jpg images under query directory C:\\Data_Competitions\\Facebook image matching\\FB_image_matching_competition\\data\\query_images\\\n",
      "detect 1000000 jpg images under reference directory C:\\Data_Competitions\\Facebook image matching\\FB_image_matching_competition\\data\\reference_images\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detect 1000000 jpg images under directory C:\\Data_Competitions\\Facebook image matching\\FB_image_matching_competition\\data\\training_images\\\n",
      "detect 4991 number of ground truth pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [05:30<00:00,  1.65s/it]\n",
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, total triplets: 197227, average loss per batch: 0.14587855949997902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [05:28<00:00,  1.64s/it]\n",
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, total triplets: 193997, average loss per batch: 0.14512887582182885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [05:35<00:00,  1.68s/it]\n",
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, total triplets: 193931, average loss per batch: 0.144635114595294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [05:26<00:00,  1.63s/it]\n",
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, total triplets: 191736, average loss per batch: 0.14432828724384308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [05:23<00:00,  1.62s/it]\n",
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, total triplets: 189784, average loss per batch: 0.14409638337790967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [05:28<00:00,  1.64s/it]\n",
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, total triplets: 188776, average loss per batch: 0.14460732735693455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [06:09<00:00,  1.85s/it]\n",
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, total triplets: 187818, average loss per batch: 0.14440894782543182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [06:11<00:00,  1.86s/it]\n",
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, total triplets: 186284, average loss per batch: 0.14465362809598445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [05:44<00:00,  1.72s/it]\n",
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, total triplets: 186588, average loss per batch: 0.14404310181736946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [05:35<00:00,  1.68s/it]\n",
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, total triplets: 185658, average loss per batch: 0.14445452190935612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [05:34<00:00,  1.67s/it]\n",
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, total triplets: 184480, average loss per batch: 0.14378141567111016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [05:37<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11, total triplets: 183896, average loss per batch: 0.143377720490098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from FBImageTriplet import FBImgMatchingDataSetTriplet, TripletLoss\n",
    "dataset = FBImgMatchingDataSetTriplet(query_image_path, ref_image_path, training_image_path, ground_truth_csv, data_transforms['train'])\n",
    "\n",
    "# train model\n",
    "tt_epoch = 12\n",
    "margin = 0.3\n",
    "model.train()\n",
    "for epoch in range(tt_epoch):\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=25, shuffle=False, num_workers=2)\n",
    "    progress_bar = tqdm(dataloader)\n",
    "    num_valid_training_triplets = 0\n",
    "    total_triplet_loss = 0\n",
    "    number_batches = 0\n",
    "    for anchor_imgs, pos_imgs, neg_imgstacks, idxs in progress_bar:\n",
    "        # get all images from this mini batch\n",
    "        anchor_img_size = anchor_imgs.size(0)\n",
    "        pos_img_size = pos_imgs.size(0)\n",
    "        neg_imgs = torch.flatten(neg_imgstacks, start_dim=0, end_dim=1)   # reshape the neg imgs as each index return multiple negative images, so we need to multiply the batch size. example output dimension: [10,3,224,224]\n",
    "        neg_img_size = neg_imgs.size(0)\n",
    "        all_imgs = torch.cat((anchor_imgs,pos_imgs, neg_imgs))  # example output dimension  [120,3,224,224]\n",
    "        all_imgs = all_imgs.to(device)\n",
    "        \n",
    "        # feed all image to the model and get the corresponding embedding\n",
    "        embeddings = model(all_imgs)  # example output size: torch.Size([120, 512])\n",
    "        anchor_embedding = embeddings[:anchor_img_size]\n",
    "        pos_embedding = embeddings[anchor_img_size:anchor_img_size + pos_img_size]\n",
    "        neg_embedding = embeddings[anchor_img_size + pos_img_size:]\n",
    "        \n",
    "        # generate triplets\n",
    "        selected_anchor_embeddings, selected_pos_embeddings, selected_neg_embeddings = generate_triplets(anchor_embedding, pos_embedding, neg_embedding, margin = margin)\n",
    "        \n",
    "        # calculate triplet loss\n",
    "        triplet_loss = TripletLoss(margin=margin).forward(\n",
    "            anchor=selected_anchor_embeddings,\n",
    "            positive=selected_pos_embeddings,\n",
    "            negative=selected_neg_embeddings\n",
    "        )\n",
    "        \n",
    "        # calculate statistics\n",
    "        num_valid_training_triplets += selected_anchor_embeddings.size(0)\n",
    "        total_triplet_loss += triplet_loss.item()\n",
    "        number_batches += 1\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer_model.zero_grad()\n",
    "        triplet_loss.backward()\n",
    "        optimizer_model.step()\n",
    "        \n",
    "    # output log\n",
    "    print(\"epoch: {}, total triplets: {}, average loss per batch: {}\".format(epoch, num_valid_training_triplets, total_triplet_loss/number_batches))\n",
    "    \n",
    "# store model\n",
    "state = {\n",
    "    'epoch': tt_epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_model_state_dict': optimizer_model.state_dict()\n",
    "}\n",
    "    \n",
    "torch.save(state, 'resnet34_semihard12.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "add28fcd-d950-459c-8b86-bbebb5b0696b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8dab80d-f328-4768-8d3f-dac65ee6dabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe4e364-4892-45f1-9780-0a76daa3b76e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
